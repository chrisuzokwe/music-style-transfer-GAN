{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation\t Adam\t BatchNormalization\t Conv2D\t Dense\t Dropout\t Flatten\t Input\t LeakyReLU\t \n",
      "Model\t Reshape\t Sequential\t UpSampling2D\t ZeroPadding2D\t build_discriminator\t build_generator\t channels\t combined\t \n",
      "discriminator\t division\t freq_rows\t generator\t img\t img_shape\t latent_dim\t mnist\t np\t \n",
      "optimizer\t plt\t print_function\t sys\t tf\t time_cols\t valid\t z\t \n"
     ]
    }
   ],
   "source": [
    "who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_rows = 1025\n",
    "time_cols = 313\n",
    "channels = 1\n",
    "latent_dim = (freq_rows, time_cols, channels)\n",
    "img_shape = (freq_rows, time_cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(4*4*256, activation=\"relu\", input_dim=320825))\n",
    "    model.add(Reshape((256, 4 ,4)))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    print(\"GENERATOR\")\n",
    "    model.summary()\n",
    "\n",
    "    noise = Input(shape=(320825,))\n",
    "    remix = model(noise)\n",
    "\n",
    "    return Model(noise, remix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    print(\"DISCRIMINATOR\")\n",
    "    model.summary()\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISCRIMINATOR\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_67 (Conv2D)           (None, 513, 157, 32)      320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)   (None, 513, 157, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 513, 157, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 257, 79, 64)       18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPaddi (None, 258, 80, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 258, 80, 64)       256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)   (None, 258, 80, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 258, 80, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 129, 40, 128)      73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 129, 40, 128)      512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)   (None, 129, 40, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 129, 40, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 129, 40, 256)      295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 129, 40, 256)      1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)   (None, 129, 40, 256)      0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 129, 40, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1320960)           0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 1320961   \n",
      "=================================================================\n",
      "Total params: 1,710,593\n",
      "Trainable params: 1,709,697\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "GENERATOR\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 4096)              1314103296\n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 256, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_13 (UpSampling (None, 512, 8, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 512, 8, 256)       9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 512, 8, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 512, 8, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_14 (UpSampling (None, 1024, 16, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 1024, 16, 128)     295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 1024, 16, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1024, 16, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 1024, 16, 1)       1153      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 1024, 16, 1)       0         \n",
      "=================================================================\n",
      "Total params: 1,314,410,497\n",
      "Trainable params: 1,314,409,729\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator()\n",
    "\n",
    "# The generator takes noise as input and generates imgs\n",
    "z = Input(shape=(320825,))\n",
    "img = generator(z)\n",
    "\n",
    "# For the combined model we will only train the generator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# The discriminator takes generated images as input and determines validity\n",
    "valid = discriminator(img)\n",
    "\n",
    "# The combined model  (stacked generator and discriminator)\n",
    "# Trains the generator to fool the discriminator\n",
    "combined = Model(z, valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
